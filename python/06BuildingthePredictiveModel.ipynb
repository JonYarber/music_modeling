{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed8a75a-02b9-46fa-b988-e7248d3527a8",
   "metadata": {},
   "source": [
    "<a id='top'></a> \n",
    "\n",
    "# Building the Predictive Model\n",
    "In this notebook, we will build a Recurrent Neural Network (RNN) using a song's timbre from Spotify's audio analysis to cluster songs that sound alike, and use the results to train an unsupervised learning model that will return 'like' songs.<br>\n",
    "\n",
    "*Unfortunately, while I was working on this portion of the project, Spotify shut down access to the audio analysis. I was able to acquire data for over 500,000 songs, but many of them were not useful for building the final product I desired, and it was not enough. By the time I figured how to adjust my methodology to pull more relevant songs, the access had been cut-off. As a result, this notebook serves to explain the build of the RNN and the result.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68a639-7ecd-403a-8175-32d52ee1ab67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e91a8c-9f59-4089-931e-9ab39c36566d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "[1) Setting Up the API Connection](https://nbviewer.org/github/JonYarber/music_modeling/blob/main/python/01SettingUptheAPIConnection.ipynb)<br>\n",
    "[2) Using the Spotify API](https://nbviewer.org/github/JonYarber/music_modeling/blob/main/python/02UsingtheSpotifyAPI.ipynb)<br>\n",
    "[3) Spotify Audio Data Insights](https://nbviewer.org/github/JonYarber/music_modeling/blob/main/python/03SpotifyAudioDataInsights.ipynb)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2768c-47d9-4ad0-bc97-58585178304f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2040d-116f-4c34-bcab-e104ca02b92b",
   "metadata": {},
   "source": [
    "<a id='AcquiringTimbres'></a>\n",
    "\n",
    "## Acquiring Timbres\n",
    "Since the plan was to build a machine learning model, I needed to pull a large number of track timbres for analysis. This came with several challenges:\n",
    "<h3>Rate Limiting</h3>\n",
    "Spotify enforces strict rate limits on API calls. When I ran a large volume of searches or tried to retrieve bulk audio analyses, I was cut off from the API within minutes.<br>\n",
    "I initially added a pause, limiting requests to only a couple per minute, but even at that rate I was still blocked after an hour or two.<br>\n",
    "<br>\n",
    "<b>Solution:</b> I set up multiple API keys. When the rate limit was exceeded on one key, another could take over.<br>\n",
    "Even with this workaround, I still had to keep the request rate low, so retrieving track URIs and timbres became a days-long process.\n",
    "<h3>Finding Track URIs</h3>\n",
    "From <a href = \"https://nbviewer.org/github/JonYarber/music_modeling/blob/main/python/03SpotifyAudioDataInsights.ipynb\">Spotify Audio Data Insights</a> we know that a track URI is required to retrieve timbre data using the <code>audio_analysis</code> method. From <a href=\"https://nbviewer.org/github/JonYarber/music_modeling/blob/main/python/02UsingtheSpotifyAPI.ipynb\">Using the Spotify API</a> we know that the <code>search</code> method can be used to retreive track URIs. But exactly should we feed into the search to generate URIs?<br>\n",
    "<br>\n",
    "<b>Solution:</b> A key line in  <a href=\"https://nbviewer.org/github/JonYarber/music_modeling/blob/main/python/02UsingtheSpotifyAPI.ipynb\">Using the Spotify API</a> came in handy here:<br>\n",
    "        <blockquote><i>The <code>search</code> function will always return the specified number of results... regardless of how good a \n",
    "            match the result is.</blockquote></i>\n",
    "I leveraged this “fuzzy matching” behavior by writing an algorithm that iterated through the alphabet, stringing together various letter combinations one at a time. This worked, but introduced another problem.\n",
    "<h3>Picking Up Where I Left Off</h3>\n",
    "If I was generating random letter combinations, how could I resume from the right place once the API cut me off due to rate limits?<br>\n",
    "<br>\n",
    "<b>Solution:</b> I built another algorithm that converted the last search sequence into an index (a number), then picked up from the next sequence when restarted.<br>\n",
    "<b>Example:</b> If the last search term was \"ab\", that represented the 27th search. The next term (\"ac\") would then be search number 28.\n",
    "<h3>Data Management</h3>\n",
    "Timbre is recorded per microsecond of a song, so the entire timbre profile for just one song is hundreds or thousands of arrays of length 12. That's a lot of data. Since my goal was to collect over a million track timbres, I needed an efficient way to store and manage all this data.</b>\n",
    "<br>\n",
    "<b>Solution:</b> I built a MySQL database in DBeaver, which made it much easier to organize and query the growing dataset.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fc3d5-9728-4669-8c94-632829e04844",
   "metadata": {},
   "source": [
    "<a id='TimbrePipeline'></a>\n",
    "\n",
    "## The Pipeline\n",
    "Once all of these challenges were addressed, I constructed a pipeline that would:\n",
    "<ol>\n",
    "    <li>Rotate through API keys whenever a rate limit was reached.</li> \n",
    "    <li>Search for track URIs using the <code>search</code> method and my <code>create_search_term()</code> function.</li>\n",
    "    <li>Store each retrieved <code>track_uri</code>, <code>track_name</code>, <code>artist_uri</code>, and the <code>search_term</code> used in the <b>tracks</b> table in the DB.</li>\n",
    "    <li>Store each retreived <code>artist_uri</code> and <code>artist_name</code> in the <b>artists</b> table in the DB.</li>\n",
    "    <li>When the rate limit was met or more track URIs were required, use the last <code>search_term</code> in my from my <b>tracks</b>\n",
    "        table and my <code>get_next_term()</code> function to generate the next search term and continue.</li>\n",
    "    <li>Once a set number of track URIs were collected, call the <code>audio_analysis</code> method on those URIs. Store each <code>track_uri</code> and its <code>track_timbre</code> in the <b>timbres</b> table in the DB.</li>\n",
    "</ol>\n",
    "Sound simple? <b>It wasn’t!</b><br>\n",
    "Along the way, I learned a lot about error handling, batching requests, and working around rate limitations. While I’m not uploading a notebook that explains this process in detail (since the approach no longer works), the Python script GetAppendTimbres.py can still be found in the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1f844-ba8b-4373-b604-41402c3c3002",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b444ee06-9698-46e4-8238-7d244a361436",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009fa999-d657-46da-b9a6-dee5f6df288d",
   "metadata": {},
   "source": [
    "### Get Timbre Dataframe\n",
    "\n",
    "Load the acquired track timbres from my database. Only load songs of a minimum length (<code>min_segments</code>) and <code>popularity</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea620bff-4d87-4526-b470-c5382ff4f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timbre_df(min_popularity, min_segments):\n",
    "    \n",
    "    print(\"Building timbre DF from DB.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    timbre_query = \"\"\"SELECT \n",
    "                        \tt.track_name,\n",
    "                        \ta.artist_name,\n",
    "                        \tt.popularity,\n",
    "                        \ttim.track_timbre\n",
    "                        FROM timbres tim\n",
    "                        LEFT JOIN tracks t ON t.track_uri = tim.track_uri\n",
    "                        LEFT JOIN artists a ON a.artist_uri = t.artist_uri\n",
    "                        WHERE popularity > %s \n",
    "                            AND JSON_LENGTH(track_timbre) > %s\"\"\"\n",
    "                      \n",
    "    timbre_df = pd.read_sql(timbre_query, \n",
    "                            con = engine, \n",
    "                            params = (min_popularity, min_segments))\n",
    "    \n",
    "    print(f\"Timbre DF loaded in {round(time.time() - start_time)} seconds.\")\n",
    "\n",
    "    print(\"Applying JSON loads.\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fix timbre DF\n",
    "    timbre_df['track_timbre'] = timbre_df.track_timbre.apply(json.loads)\n",
    "    \n",
    "    print(f\"JSON load took {round(time.time() - start_time)} seconds to execute.\")\n",
    "    \n",
    "    print(f\"Final timbre data frame: {len(timbre_df)} rows.\")\n",
    "\n",
    "    return timbre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59671a70-6fda-4c8b-b4ce-304f88982a2d",
   "metadata": {},
   "source": [
    "### Get Middle Portion\n",
    "\n",
    "Because tracks of different lengths (number of features), we have to make them all the same length. For this, I opted to just pull the middle portions of the tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17036bc-e493-4db4-bdbc-9f3e58e33c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_portion(vectors, target_length):\n",
    "    \n",
    "    length = len(vectors)\n",
    "    \n",
    "    if length >= target_length:\n",
    "        start_idx = (length - target_length) // 2\n",
    "        end_idx = start_idx + target_length\n",
    "        return vectors[start_idx:end_idx]\n",
    "    else:\n",
    "        padding_needed = target_length - length\n",
    "        return vectors + [[0] * 12] * padding_needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656370e-6734-4f06-88d0-a8df28709657",
   "metadata": {},
   "source": [
    "### Clean Timbre Dataframe\n",
    "\n",
    "Use the <code>get_middle_portion()</code> function, flatten the timbres, and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102ca16-dbb2-4f5f-875b-08137ce254b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_timbres(timbres, final_length):\n",
    "    \n",
    "    segments = np.array([get_middle_portion(seq, final_length) for seq in timbres])\n",
    "\n",
    "    segments_scaled = StandardScaler().fit_transform(segments.reshape(-1, 1))\n",
    "    \n",
    "    segments_scaled = MinMaxScaler(feature_range=(-1, 1)).fit_transform(segments_scaled)\n",
    "    \n",
    "    segments_scaled = segments_scaled.reshape(len(timbres), final_length, 12)\n",
    "    \n",
    "    return list(segments_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afe0bb7-282a-4352-83ae-b3a3cc6c5591",
   "metadata": {},
   "source": [
    "### Build Autoencoder\n",
    "\n",
    "Here's what we've all been waiting for: <b>the brain</b>.<br>\n",
    "This is RNN which compresses these tracks with millions of parameters down to just two numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f0012-d3d1-4d66-8eaf-778c43712b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(num_segments):\n",
    "    \n",
    "    encoder_input = layers.Input(shape=(num_segments, 12),name='encoder_input')\n",
    "    \n",
    "    encode_conv1d_16 = layers.Conv1D(16,kernel_size=10,activation='relu',name='encode_conv1d_16',padding='same')(encoder_input)\n",
    "    \n",
    "    encode_conv1d_32 = layers.Conv1D(32,kernel_size=10, activation='relu',name='encode_conv1d_32',padding='same')(encode_conv1d_16)\n",
    "    \n",
    "    encode_conv1d_64 = layers.Conv1D(64,kernel_size=10,activation='relu',name='encode_conv1d_64',padding='same')(encode_conv1d_32)\n",
    "    \n",
    "    encode_lstm = layers.LSTM(128,activation='tanh',return_sequences=False, name='encode_lstm')(encode_conv1d_64)\n",
    "    \n",
    "    encode_dense_64 = layers.Dense(64,activation='relu',name='encode_dense_64')(encode_lstm)\n",
    "    \n",
    "    encode_dense_32 = layers.Dense(32,activation='relu',name='encode_dense_32')(encode_dense_64)\n",
    "    \n",
    "    latent_layer = layers.Dense(2,activation='linear',name='latent_layer')(encode_dense_32)\n",
    "    \n",
    "    decode_dense_32 = layers.Dense(32,activation='relu',name='decode_dense_32')(latent_layer)\n",
    "    \n",
    "    decode_dense_64 = layers.Dense(64,activation='relu',name='decode_dense_64')(decode_dense_32)\n",
    "    \n",
    "    #decode_dense_128 = layers.Dense(128,activation='relu',name='decode_dense_128')(decode_dense_64)\n",
    "    \n",
    "    decode_dense_expand = layers.Dense(num_segments*64,activation='relu',name='decode_dense_expand')(decode_dense_64)\n",
    "    \n",
    "    decoder_reshape = layers.Reshape((num_segments,64),name='decoder_reshape')(decode_dense_expand)\n",
    "    \n",
    "    decode_lstm = layers.LSTM(128,activation='tanh',return_sequences=True,name='decode_lstm')(decoder_reshape)\n",
    "    \n",
    "    decode_conv1d_64 = layers.Conv1D(64,activation='relu',kernel_size=10,name='decode_conv1d_64',padding='same')(decode_lstm)\n",
    "    \n",
    "    decode_conv1d_32 = layers.Conv1D(32,activation='relu',kernel_size=10,name='decode_conv1d_32',padding='same')(decode_conv1d_64)\n",
    "    \n",
    "    decode_conv1d_16 = layers.Conv1D(16,activation='relu',kernel_size=10,name='decode_conv1d_16',padding='same')(decode_conv1d_32)\n",
    "    \n",
    "    output_layer = layers.Conv1D(12,activation='linear',kernel_size=10,name='output_layer',padding='same')(decode_conv1d_16)\n",
    "    \n",
    "    autoencoder = models.Model(inputs=encoder_input, outputs=output_layer,name='my_model')\n",
    "\n",
    "    return autoencoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify (Python 3.11.11)",
   "language": "python",
   "name": "spotify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
